{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5bd8a8f4",
   "metadata": {},
   "source": [
    "# MODULE 3\n",
    "---\n",
    "## Task Summary\n",
    "- Filter 5+ items basket\n",
    "- Model that predicts whether the customer will buy the item or not\n",
    "- TARGET: Increase monthly sales by 2% and boost selected items >25%\n",
    "\n",
    "### Exploration phase\n",
    "1. Filter data to orders with 5+ items\n",
    "2. Just linear models with 3-way split (train/validation/test)\n",
    "3. Select a final model to move to the next step\n",
    "\n",
    "### MVP Code\n",
    "Production-ready code for our pipeline\n",
    "1. Data loading\n",
    "2. Preprocessing\n",
    "3. Model training/selection: train different models and evaluate performance. Train a final model and save. Think what is a good standard to save the trained models to keep track of the history of the models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "18c9d08e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import os\n",
    "from dotenv import find_dotenv, load_dotenv\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75def626",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find .env\n",
    "dotenv_path = find_dotenv()\n",
    "# Load entries as environment variables\n",
    "load_dotenv(dotenv_path)\n",
    "\n",
    "# Get .env variables\n",
    "ACCESS_KEY_ID = os.getenv('ACCESS_KEY_ID')\n",
    "SECRET_ACCESS_KEY = os.getenv('SECRET_ACCESS_KEY')\n",
    "\n",
    "s3_client = boto3.client(\n",
    "    's3',\n",
    "    aws_access_key_id=ACCESS_KEY_ID,\n",
    "    aws_secret_access_key=SECRET_ACCESS_KEY\n",
    ")\n",
    "\n",
    "s3_resource = boto3.resource('s3')\n",
    "\n",
    "response = s3_client.list_objects_v2(Bucket='zrive-ds-data')\n",
    "objects = response.get('Contents', [])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96ad25b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Search for .csv files\n",
    "for obj in objects:\n",
    "    key = obj['Key']\n",
    "    if key.endswith('.csv'):\n",
    "        print(key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8d75a32",
   "metadata": {},
   "outputs": [],
   "source": [
    "s3_client.download_file(Bucket = 'zrive-ds-data', \n",
    "                        Key = 'groceries/box_builder_dataset/feature_frame.csv',\n",
    "                        Filename = 'feature_frame.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f493f02e",
   "metadata": {},
   "source": [
    "## Filtering data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a21f0354",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>variant_id</th>\n",
       "      <th>product_type</th>\n",
       "      <th>order_id</th>\n",
       "      <th>user_id</th>\n",
       "      <th>created_at</th>\n",
       "      <th>order_date</th>\n",
       "      <th>user_order_seq</th>\n",
       "      <th>outcome</th>\n",
       "      <th>ordered_before</th>\n",
       "      <th>abandoned_before</th>\n",
       "      <th>active_snoozed</th>\n",
       "      <th>set_as_regular</th>\n",
       "      <th>normalised_price</th>\n",
       "      <th>discount_pct</th>\n",
       "      <th>vendor</th>\n",
       "      <th>global_popularity</th>\n",
       "      <th>count_adults</th>\n",
       "      <th>count_children</th>\n",
       "      <th>count_babies</th>\n",
       "      <th>count_pets</th>\n",
       "      <th>people_ex_baby</th>\n",
       "      <th>days_since_purchase_variant_id</th>\n",
       "      <th>avg_days_to_buy_variant_id</th>\n",
       "      <th>std_days_to_buy_variant_id</th>\n",
       "      <th>days_since_purchase_product_type</th>\n",
       "      <th>avg_days_to_buy_product_type</th>\n",
       "      <th>std_days_to_buy_product_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2880544</th>\n",
       "      <td>33826439594116</td>\n",
       "      <td>healthcarevitamins</td>\n",
       "      <td>3643254800516</td>\n",
       "      <td>3893722808452</td>\n",
       "      <td>2021-03-03 13:19:28</td>\n",
       "      <td>2021-03-03 00:00:00</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.417186</td>\n",
       "      <td>0.11436</td>\n",
       "      <td>colief</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>27.693045</td>\n",
       "      <td>30.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>27.451392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2880545</th>\n",
       "      <td>33826439594116</td>\n",
       "      <td>healthcarevitamins</td>\n",
       "      <td>3643274788996</td>\n",
       "      <td>3883757174916</td>\n",
       "      <td>2021-03-03 13:57:35</td>\n",
       "      <td>2021-03-03 00:00:00</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.417186</td>\n",
       "      <td>0.11436</td>\n",
       "      <td>colief</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>27.693045</td>\n",
       "      <td>30.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>27.451392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2880546</th>\n",
       "      <td>33826439594116</td>\n",
       "      <td>healthcarevitamins</td>\n",
       "      <td>3643283734660</td>\n",
       "      <td>3874925314180</td>\n",
       "      <td>2021-03-03 14:14:24</td>\n",
       "      <td>2021-03-03 00:00:00</td>\n",
       "      <td>7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.417186</td>\n",
       "      <td>0.11436</td>\n",
       "      <td>colief</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>27.693045</td>\n",
       "      <td>30.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>27.451392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2880547</th>\n",
       "      <td>33826439594116</td>\n",
       "      <td>healthcarevitamins</td>\n",
       "      <td>3643294515332</td>\n",
       "      <td>3906490826884</td>\n",
       "      <td>2021-03-03 14:30:30</td>\n",
       "      <td>2021-03-03 00:00:00</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.417186</td>\n",
       "      <td>0.11436</td>\n",
       "      <td>colief</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>27.693045</td>\n",
       "      <td>30.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>27.451392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2880548</th>\n",
       "      <td>33826439594116</td>\n",
       "      <td>healthcarevitamins</td>\n",
       "      <td>3643301986436</td>\n",
       "      <td>3914253959300</td>\n",
       "      <td>2021-03-03 14:42:05</td>\n",
       "      <td>2021-03-03 00:00:00</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.417186</td>\n",
       "      <td>0.11436</td>\n",
       "      <td>colief</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>27.693045</td>\n",
       "      <td>30.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>27.451392</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             variant_id        product_type       order_id        user_id  \\\n",
       "2880544  33826439594116  healthcarevitamins  3643254800516  3893722808452   \n",
       "2880545  33826439594116  healthcarevitamins  3643274788996  3883757174916   \n",
       "2880546  33826439594116  healthcarevitamins  3643283734660  3874925314180   \n",
       "2880547  33826439594116  healthcarevitamins  3643294515332  3906490826884   \n",
       "2880548  33826439594116  healthcarevitamins  3643301986436  3914253959300   \n",
       "\n",
       "                  created_at           order_date  user_order_seq  outcome  \\\n",
       "2880544  2021-03-03 13:19:28  2021-03-03 00:00:00               3      0.0   \n",
       "2880545  2021-03-03 13:57:35  2021-03-03 00:00:00               4      0.0   \n",
       "2880546  2021-03-03 14:14:24  2021-03-03 00:00:00               7      0.0   \n",
       "2880547  2021-03-03 14:30:30  2021-03-03 00:00:00               2      0.0   \n",
       "2880548  2021-03-03 14:42:05  2021-03-03 00:00:00               3      0.0   \n",
       "\n",
       "         ordered_before  abandoned_before  active_snoozed  set_as_regular  \\\n",
       "2880544             0.0               0.0             0.0             0.0   \n",
       "2880545             0.0               0.0             0.0             0.0   \n",
       "2880546             0.0               0.0             0.0             0.0   \n",
       "2880547             0.0               0.0             0.0             0.0   \n",
       "2880548             0.0               0.0             0.0             0.0   \n",
       "\n",
       "         normalised_price  discount_pct  vendor  global_popularity  \\\n",
       "2880544          0.417186       0.11436  colief                0.0   \n",
       "2880545          0.417186       0.11436  colief                0.0   \n",
       "2880546          0.417186       0.11436  colief                0.0   \n",
       "2880547          0.417186       0.11436  colief                0.0   \n",
       "2880548          0.417186       0.11436  colief                0.0   \n",
       "\n",
       "         count_adults  count_children  count_babies  count_pets  \\\n",
       "2880544           2.0             0.0           0.0         0.0   \n",
       "2880545           2.0             0.0           0.0         0.0   \n",
       "2880546           2.0             0.0           0.0         0.0   \n",
       "2880547           2.0             0.0           0.0         0.0   \n",
       "2880548           2.0             0.0           0.0         0.0   \n",
       "\n",
       "         people_ex_baby  days_since_purchase_variant_id  \\\n",
       "2880544             2.0                            33.0   \n",
       "2880545             2.0                            33.0   \n",
       "2880546             2.0                            33.0   \n",
       "2880547             2.0                            33.0   \n",
       "2880548             2.0                            33.0   \n",
       "\n",
       "         avg_days_to_buy_variant_id  std_days_to_buy_variant_id  \\\n",
       "2880544                        34.0                   27.693045   \n",
       "2880545                        34.0                   27.693045   \n",
       "2880546                        34.0                   27.693045   \n",
       "2880547                        34.0                   27.693045   \n",
       "2880548                        34.0                   27.693045   \n",
       "\n",
       "         days_since_purchase_product_type  avg_days_to_buy_product_type  \\\n",
       "2880544                              30.0                          34.0   \n",
       "2880545                              30.0                          34.0   \n",
       "2880546                              30.0                          34.0   \n",
       "2880547                              30.0                          34.0   \n",
       "2880548                              30.0                          34.0   \n",
       "\n",
       "         std_days_to_buy_product_type  \n",
       "2880544                     27.451392  \n",
       "2880545                     27.451392  \n",
       "2880546                     27.451392  \n",
       "2880547                     27.451392  \n",
       "2880548                     27.451392  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_frame = pd.read_csv('feature_frame.csv')\n",
    "feature_frame.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c13ac4e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2880549 entries, 0 to 2880548\n",
      "Data columns (total 27 columns):\n",
      " #   Column                            Dtype  \n",
      "---  ------                            -----  \n",
      " 0   variant_id                        int64  \n",
      " 1   product_type                      object \n",
      " 2   order_id                          int64  \n",
      " 3   user_id                           int64  \n",
      " 4   created_at                        object \n",
      " 5   order_date                        object \n",
      " 6   user_order_seq                    int64  \n",
      " 7   outcome                           float64\n",
      " 8   ordered_before                    float64\n",
      " 9   abandoned_before                  float64\n",
      " 10  active_snoozed                    float64\n",
      " 11  set_as_regular                    float64\n",
      " 12  normalised_price                  float64\n",
      " 13  discount_pct                      float64\n",
      " 14  vendor                            object \n",
      " 15  global_popularity                 float64\n",
      " 16  count_adults                      float64\n",
      " 17  count_children                    float64\n",
      " 18  count_babies                      float64\n",
      " 19  count_pets                        float64\n",
      " 20  people_ex_baby                    float64\n",
      " 21  days_since_purchase_variant_id    float64\n",
      " 22  avg_days_to_buy_variant_id        float64\n",
      " 23  std_days_to_buy_variant_id        float64\n",
      " 24  days_since_purchase_product_type  float64\n",
      " 25  avg_days_to_buy_product_type      float64\n",
      " 26  std_days_to_buy_product_type      float64\n",
      "dtypes: float64(19), int64(4), object(4)\n",
      "memory usage: 593.4+ MB\n"
     ]
    }
   ],
   "source": [
    "feature_frame.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2cb04209",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3446"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(feature_frame['order_id'].drop_duplicates().dropna())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2e2ff434",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(2603)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(feature_frame.groupby('order_id')['outcome'].sum()>=5).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fe2f75f",
   "metadata": {},
   "source": [
    "We have 3446 different baskets -> 2603 with 5+ items bought"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4335c002",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = feature_frame.groupby('order_id')['outcome'].sum().ge(5)\n",
    "order_ids_filtered = mask.index[mask].to_list()\n",
    "df_feature = feature_frame[feature_frame['order_id'].isin(order_ids_filtered)].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a441b3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 2163953 entries, 0 to 2880547\n",
      "Data columns (total 27 columns):\n",
      " #   Column                            Dtype  \n",
      "---  ------                            -----  \n",
      " 0   variant_id                        int64  \n",
      " 1   product_type                      object \n",
      " 2   order_id                          int64  \n",
      " 3   user_id                           int64  \n",
      " 4   created_at                        object \n",
      " 5   order_date                        object \n",
      " 6   user_order_seq                    int64  \n",
      " 7   outcome                           float64\n",
      " 8   ordered_before                    float64\n",
      " 9   abandoned_before                  float64\n",
      " 10  active_snoozed                    float64\n",
      " 11  set_as_regular                    float64\n",
      " 12  normalised_price                  float64\n",
      " 13  discount_pct                      float64\n",
      " 14  vendor                            object \n",
      " 15  global_popularity                 float64\n",
      " 16  count_adults                      float64\n",
      " 17  count_children                    float64\n",
      " 18  count_babies                      float64\n",
      " 19  count_pets                        float64\n",
      " 20  people_ex_baby                    float64\n",
      " 21  days_since_purchase_variant_id    float64\n",
      " 22  avg_days_to_buy_variant_id        float64\n",
      " 23  std_days_to_buy_variant_id        float64\n",
      " 24  days_since_purchase_product_type  float64\n",
      " 25  avg_days_to_buy_product_type      float64\n",
      " 26  std_days_to_buy_product_type      float64\n",
      "dtypes: float64(19), int64(4), object(4)\n",
      "memory usage: 462.3+ MB\n"
     ]
    }
   ],
   "source": [
    "df_feature.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f9a97ac4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "variant_id                          0\n",
       "product_type                        0\n",
       "order_id                            0\n",
       "user_id                             0\n",
       "created_at                          0\n",
       "order_date                          0\n",
       "user_order_seq                      0\n",
       "outcome                             0\n",
       "ordered_before                      0\n",
       "abandoned_before                    0\n",
       "active_snoozed                      0\n",
       "set_as_regular                      0\n",
       "normalised_price                    0\n",
       "discount_pct                        0\n",
       "vendor                              0\n",
       "global_popularity                   0\n",
       "count_adults                        0\n",
       "count_children                      0\n",
       "count_babies                        0\n",
       "count_pets                          0\n",
       "people_ex_baby                      0\n",
       "days_since_purchase_variant_id      0\n",
       "avg_days_to_buy_variant_id          0\n",
       "std_days_to_buy_variant_id          0\n",
       "days_since_purchase_product_type    0\n",
       "avg_days_to_buy_product_type        0\n",
       "std_days_to_buy_product_type        0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_feature.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "484c4059",
   "metadata": {},
   "source": [
    "## (DON´T RUN THIS PART !!!!!!!!) First approach was is bad."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4357a9d3",
   "metadata": {},
   "source": [
    "### PreProcessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0527112b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64a7ef6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "TARGET = 'outcome'\n",
    "\n",
    "GROUP = 'user_id'\n",
    "\n",
    "info_cols = ['variant_id', 'order_id', 'created_at', 'order_date']\n",
    "\n",
    "FEATURES = [col for col in df_feature.columns if col not in info_cols + [TARGET] ]\n",
    "\n",
    "# I should check if global popularity is linked to the time of purchase, or if there are some things that were bought previously that now not, etc.\n",
    "FEATURES = ['product_type_encoded', 'vendor_encoded',\n",
    "             'ordered_before', 'abandoned_before', 'set_as_regular', 'active_snoozed',\n",
    "             'price_with_discount', 'global_popularity', \n",
    "             'count_adults', 'count_children', 'count_babies', 'count_pets',\n",
    "             ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "46156f6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jontx\\AppData\\Local\\Temp\\ipykernel_18264\\3750851884.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_feature['price_with_discount'] = df_feature['normalised_price'] * (1 - df_feature['discount_pct']/100.)\n"
     ]
    }
   ],
   "source": [
    "## Creating a new column for the normalised price with discount applied\n",
    "df_feature['price_with_discount'] = df_feature['normalised_price'] * (1 - df_feature['discount_pct']/100.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "69314555",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 264 vendors and 62 products\n",
      "There are 139 unique frequencies for vendors\n"
     ]
    }
   ],
   "source": [
    "print(f'There are {df_feature.vendor.nunique()} vendors and {df_feature.product_type.nunique()} products')\n",
    "print(f'There are {df_feature.vendor.value_counts().nunique()} unique frequencies for vendors')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b58a14df",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jontx\\AppData\\Local\\Temp\\ipykernel_18264\\484010771.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_feature['vendor_encoded'] = le.transform(df_feature['vendor'])\n",
      "C:\\Users\\jontx\\AppData\\Local\\Temp\\ipykernel_18264\\484010771.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_feature['product_type_encoded'] = le.transform(df_feature['product_type'])\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>variant_id</th>\n",
       "      <th>order_id</th>\n",
       "      <th>user_id</th>\n",
       "      <th>user_order_seq</th>\n",
       "      <th>outcome</th>\n",
       "      <th>ordered_before</th>\n",
       "      <th>abandoned_before</th>\n",
       "      <th>active_snoozed</th>\n",
       "      <th>set_as_regular</th>\n",
       "      <th>normalised_price</th>\n",
       "      <th>discount_pct</th>\n",
       "      <th>global_popularity</th>\n",
       "      <th>count_adults</th>\n",
       "      <th>count_children</th>\n",
       "      <th>count_babies</th>\n",
       "      <th>count_pets</th>\n",
       "      <th>people_ex_baby</th>\n",
       "      <th>days_since_purchase_variant_id</th>\n",
       "      <th>avg_days_to_buy_variant_id</th>\n",
       "      <th>std_days_to_buy_variant_id</th>\n",
       "      <th>days_since_purchase_product_type</th>\n",
       "      <th>avg_days_to_buy_product_type</th>\n",
       "      <th>std_days_to_buy_product_type</th>\n",
       "      <th>price_with_discount</th>\n",
       "      <th>vendor_encoded</th>\n",
       "      <th>product_type_encoded</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2.163953e+06</td>\n",
       "      <td>2.163953e+06</td>\n",
       "      <td>2.163953e+06</td>\n",
       "      <td>2.163953e+06</td>\n",
       "      <td>2.163953e+06</td>\n",
       "      <td>2.163953e+06</td>\n",
       "      <td>2.163953e+06</td>\n",
       "      <td>2.163953e+06</td>\n",
       "      <td>2.163953e+06</td>\n",
       "      <td>2.163953e+06</td>\n",
       "      <td>2.163953e+06</td>\n",
       "      <td>2.163953e+06</td>\n",
       "      <td>2.163953e+06</td>\n",
       "      <td>2.163953e+06</td>\n",
       "      <td>2.163953e+06</td>\n",
       "      <td>2.163953e+06</td>\n",
       "      <td>2.163953e+06</td>\n",
       "      <td>2.163953e+06</td>\n",
       "      <td>2.163953e+06</td>\n",
       "      <td>2.163953e+06</td>\n",
       "      <td>2.163953e+06</td>\n",
       "      <td>2.163953e+06</td>\n",
       "      <td>2.163953e+06</td>\n",
       "      <td>2.163953e+06</td>\n",
       "      <td>2.163953e+06</td>\n",
       "      <td>2.163953e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>3.401022e+13</td>\n",
       "      <td>2.970615e+12</td>\n",
       "      <td>3.731338e+12</td>\n",
       "      <td>3.414455e+00</td>\n",
       "      <td>1.447767e-02</td>\n",
       "      <td>2.548530e-02</td>\n",
       "      <td>7.416982e-04</td>\n",
       "      <td>2.844794e-03</td>\n",
       "      <td>4.285213e-03</td>\n",
       "      <td>1.271294e-01</td>\n",
       "      <td>1.864700e-01</td>\n",
       "      <td>1.078504e-02</td>\n",
       "      <td>2.023446e+00</td>\n",
       "      <td>6.875196e-02</td>\n",
       "      <td>4.074488e-03</td>\n",
       "      <td>6.584801e-02</td>\n",
       "      <td>2.092198e+00</td>\n",
       "      <td>3.316272e+01</td>\n",
       "      <td>3.529397e+01</td>\n",
       "      <td>2.650028e+01</td>\n",
       "      <td>3.172204e+01</td>\n",
       "      <td>3.090521e+01</td>\n",
       "      <td>2.596460e+01</td>\n",
       "      <td>1.269080e-01</td>\n",
       "      <td>1.240767e+02</td>\n",
       "      <td>3.088828e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2.775294e+11</td>\n",
       "      <td>2.377644e+11</td>\n",
       "      <td>1.845180e+11</td>\n",
       "      <td>2.287832e+00</td>\n",
       "      <td>1.194490e-01</td>\n",
       "      <td>1.575938e-01</td>\n",
       "      <td>2.722404e-02</td>\n",
       "      <td>5.326070e-02</td>\n",
       "      <td>6.532115e-02</td>\n",
       "      <td>1.267182e-01</td>\n",
       "      <td>1.936836e-01</td>\n",
       "      <td>1.663036e-02</td>\n",
       "      <td>2.384079e-01</td>\n",
       "      <td>3.656065e-01</td>\n",
       "      <td>6.370156e-02</td>\n",
       "      <td>3.419694e-01</td>\n",
       "      <td>4.419435e-01</td>\n",
       "      <td>4.094441e+00</td>\n",
       "      <td>1.055518e+01</td>\n",
       "      <td>7.137545e+00</td>\n",
       "      <td>1.333857e+01</td>\n",
       "      <td>4.308186e+00</td>\n",
       "      <td>3.256241e+00</td>\n",
       "      <td>1.265253e-01</td>\n",
       "      <td>7.460350e+01</td>\n",
       "      <td>1.733632e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>3.361529e+13</td>\n",
       "      <td>2.807986e+12</td>\n",
       "      <td>3.046041e+12</td>\n",
       "      <td>2.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.599349e-02</td>\n",
       "      <td>-4.016064e-02</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.414214e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>7.000000e+00</td>\n",
       "      <td>2.828427e+00</td>\n",
       "      <td>1.595012e-02</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>3.380354e+13</td>\n",
       "      <td>2.872605e+12</td>\n",
       "      <td>3.528874e+12</td>\n",
       "      <td>2.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>5.394416e-02</td>\n",
       "      <td>8.633094e-02</td>\n",
       "      <td>1.633987e-03</td>\n",
       "      <td>2.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>2.000000e+00</td>\n",
       "      <td>3.300000e+01</td>\n",
       "      <td>3.000000e+01</td>\n",
       "      <td>2.322056e+01</td>\n",
       "      <td>3.000000e+01</td>\n",
       "      <td>2.800000e+01</td>\n",
       "      <td>2.427618e+01</td>\n",
       "      <td>5.386284e-02</td>\n",
       "      <td>5.700000e+01</td>\n",
       "      <td>1.500000e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>3.397325e+13</td>\n",
       "      <td>2.900909e+12</td>\n",
       "      <td>3.806872e+12</td>\n",
       "      <td>3.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>8.105178e-02</td>\n",
       "      <td>1.169176e-01</td>\n",
       "      <td>6.342495e-03</td>\n",
       "      <td>2.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>2.000000e+00</td>\n",
       "      <td>3.300000e+01</td>\n",
       "      <td>3.400000e+01</td>\n",
       "      <td>2.769305e+01</td>\n",
       "      <td>3.000000e+01</td>\n",
       "      <td>3.100000e+01</td>\n",
       "      <td>2.608188e+01</td>\n",
       "      <td>8.095419e-02</td>\n",
       "      <td>1.200000e+02</td>\n",
       "      <td>3.100000e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>3.428495e+13</td>\n",
       "      <td>2.920994e+12</td>\n",
       "      <td>3.869945e+12</td>\n",
       "      <td>4.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.352670e-01</td>\n",
       "      <td>2.234637e-01</td>\n",
       "      <td>1.432881e-02</td>\n",
       "      <td>2.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>2.000000e+00</td>\n",
       "      <td>3.300000e+01</td>\n",
       "      <td>4.000000e+01</td>\n",
       "      <td>3.062510e+01</td>\n",
       "      <td>3.000000e+01</td>\n",
       "      <td>3.400000e+01</td>\n",
       "      <td>2.796118e+01</td>\n",
       "      <td>1.351288e-01</td>\n",
       "      <td>1.820000e+02</td>\n",
       "      <td>4.700000e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>3.454300e+13</td>\n",
       "      <td>3.643295e+12</td>\n",
       "      <td>5.023381e+12</td>\n",
       "      <td>2.100000e+01</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.325301e+00</td>\n",
       "      <td>4.254386e-01</td>\n",
       "      <td>5.000000e+00</td>\n",
       "      <td>3.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>6.000000e+00</td>\n",
       "      <td>5.000000e+00</td>\n",
       "      <td>1.480000e+02</td>\n",
       "      <td>8.400000e+01</td>\n",
       "      <td>5.868986e+01</td>\n",
       "      <td>1.480000e+02</td>\n",
       "      <td>3.950000e+01</td>\n",
       "      <td>3.564191e+01</td>\n",
       "      <td>9.988859e-01</td>\n",
       "      <td>2.630000e+02</td>\n",
       "      <td>6.100000e+01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         variant_id      order_id       user_id  user_order_seq       outcome  \\\n",
       "count  2.163953e+06  2.163953e+06  2.163953e+06    2.163953e+06  2.163953e+06   \n",
       "mean   3.401022e+13  2.970615e+12  3.731338e+12    3.414455e+00  1.447767e-02   \n",
       "std    2.775294e+11  2.377644e+11  1.845180e+11    2.287832e+00  1.194490e-01   \n",
       "min    3.361529e+13  2.807986e+12  3.046041e+12    2.000000e+00  0.000000e+00   \n",
       "25%    3.380354e+13  2.872605e+12  3.528874e+12    2.000000e+00  0.000000e+00   \n",
       "50%    3.397325e+13  2.900909e+12  3.806872e+12    3.000000e+00  0.000000e+00   \n",
       "75%    3.428495e+13  2.920994e+12  3.869945e+12    4.000000e+00  0.000000e+00   \n",
       "max    3.454300e+13  3.643295e+12  5.023381e+12    2.100000e+01  1.000000e+00   \n",
       "\n",
       "       ordered_before  abandoned_before  active_snoozed  set_as_regular  \\\n",
       "count    2.163953e+06      2.163953e+06    2.163953e+06    2.163953e+06   \n",
       "mean     2.548530e-02      7.416982e-04    2.844794e-03    4.285213e-03   \n",
       "std      1.575938e-01      2.722404e-02    5.326070e-02    6.532115e-02   \n",
       "min      0.000000e+00      0.000000e+00    0.000000e+00    0.000000e+00   \n",
       "25%      0.000000e+00      0.000000e+00    0.000000e+00    0.000000e+00   \n",
       "50%      0.000000e+00      0.000000e+00    0.000000e+00    0.000000e+00   \n",
       "75%      0.000000e+00      0.000000e+00    0.000000e+00    0.000000e+00   \n",
       "max      1.000000e+00      1.000000e+00    1.000000e+00    1.000000e+00   \n",
       "\n",
       "       normalised_price  discount_pct  global_popularity  count_adults  \\\n",
       "count      2.163953e+06  2.163953e+06       2.163953e+06  2.163953e+06   \n",
       "mean       1.271294e-01  1.864700e-01       1.078504e-02  2.023446e+00   \n",
       "std        1.267182e-01  1.936836e-01       1.663036e-02  2.384079e-01   \n",
       "min        1.599349e-02 -4.016064e-02       0.000000e+00  1.000000e+00   \n",
       "25%        5.394416e-02  8.633094e-02       1.633987e-03  2.000000e+00   \n",
       "50%        8.105178e-02  1.169176e-01       6.342495e-03  2.000000e+00   \n",
       "75%        1.352670e-01  2.234637e-01       1.432881e-02  2.000000e+00   \n",
       "max        1.000000e+00  1.325301e+00       4.254386e-01  5.000000e+00   \n",
       "\n",
       "       count_children  count_babies    count_pets  people_ex_baby  \\\n",
       "count    2.163953e+06  2.163953e+06  2.163953e+06    2.163953e+06   \n",
       "mean     6.875196e-02  4.074488e-03  6.584801e-02    2.092198e+00   \n",
       "std      3.656065e-01  6.370156e-02  3.419694e-01    4.419435e-01   \n",
       "min      0.000000e+00  0.000000e+00  0.000000e+00    1.000000e+00   \n",
       "25%      0.000000e+00  0.000000e+00  0.000000e+00    2.000000e+00   \n",
       "50%      0.000000e+00  0.000000e+00  0.000000e+00    2.000000e+00   \n",
       "75%      0.000000e+00  0.000000e+00  0.000000e+00    2.000000e+00   \n",
       "max      3.000000e+00  1.000000e+00  6.000000e+00    5.000000e+00   \n",
       "\n",
       "       days_since_purchase_variant_id  avg_days_to_buy_variant_id  \\\n",
       "count                    2.163953e+06                2.163953e+06   \n",
       "mean                     3.316272e+01                3.529397e+01   \n",
       "std                      4.094441e+00                1.055518e+01   \n",
       "min                      0.000000e+00                0.000000e+00   \n",
       "25%                      3.300000e+01                3.000000e+01   \n",
       "50%                      3.300000e+01                3.400000e+01   \n",
       "75%                      3.300000e+01                4.000000e+01   \n",
       "max                      1.480000e+02                8.400000e+01   \n",
       "\n",
       "       std_days_to_buy_variant_id  days_since_purchase_product_type  \\\n",
       "count                2.163953e+06                      2.163953e+06   \n",
       "mean                 2.650028e+01                      3.172204e+01   \n",
       "std                  7.137545e+00                      1.333857e+01   \n",
       "min                  1.414214e+00                      0.000000e+00   \n",
       "25%                  2.322056e+01                      3.000000e+01   \n",
       "50%                  2.769305e+01                      3.000000e+01   \n",
       "75%                  3.062510e+01                      3.000000e+01   \n",
       "max                  5.868986e+01                      1.480000e+02   \n",
       "\n",
       "       avg_days_to_buy_product_type  std_days_to_buy_product_type  \\\n",
       "count                  2.163953e+06                  2.163953e+06   \n",
       "mean                   3.090521e+01                  2.596460e+01   \n",
       "std                    4.308186e+00                  3.256241e+00   \n",
       "min                    7.000000e+00                  2.828427e+00   \n",
       "25%                    2.800000e+01                  2.427618e+01   \n",
       "50%                    3.100000e+01                  2.608188e+01   \n",
       "75%                    3.400000e+01                  2.796118e+01   \n",
       "max                    3.950000e+01                  3.564191e+01   \n",
       "\n",
       "       price_with_discount  vendor_encoded  product_type_encoded  \n",
       "count         2.163953e+06    2.163953e+06          2.163953e+06  \n",
       "mean          1.269080e-01    1.240767e+02          3.088828e+01  \n",
       "std           1.265253e-01    7.460350e+01          1.733632e+01  \n",
       "min           1.595012e-02    0.000000e+00          0.000000e+00  \n",
       "25%           5.386284e-02    5.700000e+01          1.500000e+01  \n",
       "50%           8.095419e-02    1.200000e+02          3.100000e+01  \n",
       "75%           1.351288e-01    1.820000e+02          4.700000e+01  \n",
       "max           9.988859e-01    2.630000e+02          6.100000e+01  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "le = LabelEncoder()\n",
    "le.fit(df_feature['vendor'].unique())\n",
    "df_feature['vendor_encoded'] = le.transform(df_feature['vendor'])\n",
    "\n",
    "le.fit(df_feature['product_type'].unique())\n",
    "df_feature['product_type_encoded'] = le.transform(df_feature['product_type'])\n",
    "\n",
    "df_feature.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "713ff0b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['variant_id', 'product_type', 'order_id', 'user_id', 'created_at',\n",
       "       'order_date', 'user_order_seq', 'outcome', 'ordered_before',\n",
       "       'abandoned_before', 'active_snoozed', 'set_as_regular',\n",
       "       'normalised_price', 'discount_pct', 'vendor', 'global_popularity',\n",
       "       'count_adults', 'count_children', 'count_babies', 'count_pets',\n",
       "       'people_ex_baby', 'days_since_purchase_variant_id',\n",
       "       'avg_days_to_buy_variant_id', 'std_days_to_buy_variant_id',\n",
       "       'days_since_purchase_product_type', 'avg_days_to_buy_product_type',\n",
       "       'std_days_to_buy_product_type', 'price_with_discount', 'vendor_encoded',\n",
       "       'product_type_encoded'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_feature.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57bb13aa",
   "metadata": {},
   "source": [
    "### Models selection\n",
    "\n",
    "#### 1st create the splits\n",
    "- What I want to predict is whether a customer will buy or not an item. I think is a good approach not to use the same user for different sets, so I will try to have different unique users in each of the 3 sets.\n",
    "- I think that it is also important to have same products along 3 sets, to check whether the trained model for these products work for other users.\n",
    "- I also want to have users that bought the products in all sets, so I can train, test and validate positive-buyer profiles\n",
    "\n",
    "*¡¡ Using variables like 'days_since_purchase' would lead to **data leakage** because in production we won´t have this information !!*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b4f985b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedGroupKFold, GroupShuffleSplit, cross_val_score\n",
    "from sklearn.metrics import (average_precision_score, precision_score, precision_recall_curve, recall_score)\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Candidate models\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import RidgeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ccb177fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_feature[FEATURES]\n",
    "y = df_feature[TARGET]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8ab45613",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.4477671187867758\n"
     ]
    }
   ],
   "source": [
    "print(y.sum()/len(y) * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "61f1b2d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.014509003994747197\n"
     ]
    }
   ],
   "source": [
    "print(tv[TARGET].sum()/len(tv[TARGET]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91e55ac7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jontx\\OneDrive\\Documentos\\.ZRIVE Applied Data Science\\zrive-ds\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "c:\\Users\\jontx\\OneDrive\\Documentos\\.ZRIVE Applied Data Science\\zrive-ds\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "c:\\Users\\jontx\\OneDrive\\Documentos\\.ZRIVE Applied Data Science\\zrive-ds\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "c:\\Users\\jontx\\OneDrive\\Documentos\\.ZRIVE Applied Data Science\\zrive-ds\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "c:\\Users\\jontx\\OneDrive\\Documentos\\.ZRIVE Applied Data Science\\zrive-ds\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score for C = 1 on cross validation is [0. 0. 0. 0. 0.]\n",
      "Mean score for C = 1 on cross validation is 0.0\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[28]\u001b[39m\u001b[32m, line 15\u001b[39m\n\u001b[32m     13\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m a \u001b[38;5;129;01min\u001b[39;00m reg:\n\u001b[32m     14\u001b[39m     clf = LogisticRegression(C = a)\n\u001b[32m---> \u001b[39m\u001b[32m15\u001b[39m     score = \u001b[43mcross_val_score\u001b[49m\u001b[43m(\u001b[49m\u001b[43mclf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtv\u001b[49m\u001b[43m[\u001b[49m\u001b[43mFEATURES\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtv\u001b[49m\u001b[43m[\u001b[49m\u001b[43mTARGET\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgroups\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtv\u001b[49m\u001b[43m[\u001b[49m\u001b[43mGROUP\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcv\u001b[49m\u001b[43m=\u001b[49m\u001b[43msgk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscoring\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mprecision\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     16\u001b[39m     \u001b[38;5;66;03m# score_precision = cross_val_score(clf, tv[FEATURES], tv[TARGET], groups=tv[GROUP], cv=sgk)\u001b[39;00m\n\u001b[32m     17\u001b[39m     \u001b[38;5;66;03m# score_roc = score_recall = cross_val_score(clf, tv[FEATURES], tv[TARGET], groups=tv[GROUP], scoring='roc_auc')\u001b[39;00m\n\u001b[32m     19\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33mScore for C = \u001b[39m\u001b[38;5;132;01m{\u001b[39;00ma\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m on cross validation is \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mscore\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\jontx\\OneDrive\\Documentos\\.ZRIVE Applied Data Science\\zrive-ds\\.venv\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py:218\u001b[39m, in \u001b[36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    212\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    213\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[32m    214\u001b[39m         skip_parameter_validation=(\n\u001b[32m    215\u001b[39m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[32m    216\u001b[39m         )\n\u001b[32m    217\u001b[39m     ):\n\u001b[32m--> \u001b[39m\u001b[32m218\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    219\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    220\u001b[39m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[32m    221\u001b[39m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[32m    222\u001b[39m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[32m    223\u001b[39m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[32m    224\u001b[39m     msg = re.sub(\n\u001b[32m    225\u001b[39m         \u001b[33mr\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mparameter of \u001b[39m\u001b[33m\\\u001b[39m\u001b[33mw+ must be\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    226\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc.\u001b[34m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m must be\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    227\u001b[39m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[32m    228\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\jontx\\OneDrive\\Documentos\\.ZRIVE Applied Data Science\\zrive-ds\\.venv\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:677\u001b[39m, in \u001b[36mcross_val_score\u001b[39m\u001b[34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, params, pre_dispatch, error_score)\u001b[39m\n\u001b[32m    674\u001b[39m \u001b[38;5;66;03m# To ensure multimetric format is not supported\u001b[39;00m\n\u001b[32m    675\u001b[39m scorer = check_scoring(estimator, scoring=scoring)\n\u001b[32m--> \u001b[39m\u001b[32m677\u001b[39m cv_results = \u001b[43mcross_validate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    678\u001b[39m \u001b[43m    \u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m=\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    679\u001b[39m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m=\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    680\u001b[39m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[43m=\u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    681\u001b[39m \u001b[43m    \u001b[49m\u001b[43mgroups\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroups\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    682\u001b[39m \u001b[43m    \u001b[49m\u001b[43mscoring\u001b[49m\u001b[43m=\u001b[49m\u001b[43m{\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mscore\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mscorer\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    683\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcv\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcv\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    684\u001b[39m \u001b[43m    \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    685\u001b[39m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m=\u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    686\u001b[39m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m=\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    687\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpre_dispatch\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpre_dispatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    688\u001b[39m \u001b[43m    \u001b[49m\u001b[43merror_score\u001b[49m\u001b[43m=\u001b[49m\u001b[43merror_score\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    689\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    690\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m cv_results[\u001b[33m\"\u001b[39m\u001b[33mtest_score\u001b[39m\u001b[33m\"\u001b[39m]\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\jontx\\OneDrive\\Documentos\\.ZRIVE Applied Data Science\\zrive-ds\\.venv\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py:218\u001b[39m, in \u001b[36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    212\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    213\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[32m    214\u001b[39m         skip_parameter_validation=(\n\u001b[32m    215\u001b[39m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[32m    216\u001b[39m         )\n\u001b[32m    217\u001b[39m     ):\n\u001b[32m--> \u001b[39m\u001b[32m218\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    219\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    220\u001b[39m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[32m    221\u001b[39m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[32m    222\u001b[39m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[32m    223\u001b[39m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[32m    224\u001b[39m     msg = re.sub(\n\u001b[32m    225\u001b[39m         \u001b[33mr\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mparameter of \u001b[39m\u001b[33m\\\u001b[39m\u001b[33mw+ must be\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    226\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc.\u001b[34m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m must be\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    227\u001b[39m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[32m    228\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\jontx\\OneDrive\\Documentos\\.ZRIVE Applied Data Science\\zrive-ds\\.venv\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:399\u001b[39m, in \u001b[36mcross_validate\u001b[39m\u001b[34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, params, pre_dispatch, return_train_score, return_estimator, return_indices, error_score)\u001b[39m\n\u001b[32m    396\u001b[39m \u001b[38;5;66;03m# We clone the estimator to make sure that all the folds are\u001b[39;00m\n\u001b[32m    397\u001b[39m \u001b[38;5;66;03m# independent, and that it is pickle-able.\u001b[39;00m\n\u001b[32m    398\u001b[39m parallel = Parallel(n_jobs=n_jobs, verbose=verbose, pre_dispatch=pre_dispatch)\n\u001b[32m--> \u001b[39m\u001b[32m399\u001b[39m results = \u001b[43mparallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    400\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_fit_and_score\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    401\u001b[39m \u001b[43m        \u001b[49m\u001b[43mclone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    402\u001b[39m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    403\u001b[39m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    404\u001b[39m \u001b[43m        \u001b[49m\u001b[43mscorer\u001b[49m\u001b[43m=\u001b[49m\u001b[43mscorers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    405\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    406\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    407\u001b[39m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m=\u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    408\u001b[39m \u001b[43m        \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    409\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfit_params\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrouted_params\u001b[49m\u001b[43m.\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    410\u001b[39m \u001b[43m        \u001b[49m\u001b[43mscore_params\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrouted_params\u001b[49m\u001b[43m.\u001b[49m\u001b[43mscorer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mscore\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    411\u001b[39m \u001b[43m        \u001b[49m\u001b[43mreturn_train_score\u001b[49m\u001b[43m=\u001b[49m\u001b[43mreturn_train_score\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    412\u001b[39m \u001b[43m        \u001b[49m\u001b[43mreturn_times\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    413\u001b[39m \u001b[43m        \u001b[49m\u001b[43mreturn_estimator\u001b[49m\u001b[43m=\u001b[49m\u001b[43mreturn_estimator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    414\u001b[39m \u001b[43m        \u001b[49m\u001b[43merror_score\u001b[49m\u001b[43m=\u001b[49m\u001b[43merror_score\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    415\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    416\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mindices\u001b[49m\n\u001b[32m    417\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    419\u001b[39m _warn_or_raise_about_fit_failures(results, error_score)\n\u001b[32m    421\u001b[39m \u001b[38;5;66;03m# For callable scoring, the return type is only know after calling. If the\u001b[39;00m\n\u001b[32m    422\u001b[39m \u001b[38;5;66;03m# return type is a dictionary, the error scores can now be inserted with\u001b[39;00m\n\u001b[32m    423\u001b[39m \u001b[38;5;66;03m# the correct key.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\jontx\\OneDrive\\Documentos\\.ZRIVE Applied Data Science\\zrive-ds\\.venv\\Lib\\site-packages\\sklearn\\utils\\parallel.py:82\u001b[39m, in \u001b[36mParallel.__call__\u001b[39m\u001b[34m(self, iterable)\u001b[39m\n\u001b[32m     73\u001b[39m warning_filters = warnings.filters\n\u001b[32m     74\u001b[39m iterable_with_config_and_warning_filters = (\n\u001b[32m     75\u001b[39m     (\n\u001b[32m     76\u001b[39m         _with_config_and_warning_filters(delayed_func, config, warning_filters),\n\u001b[32m   (...)\u001b[39m\u001b[32m     80\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[32m     81\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m82\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config_and_warning_filters\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\jontx\\OneDrive\\Documentos\\.ZRIVE Applied Data Science\\zrive-ds\\.venv\\Lib\\site-packages\\joblib\\parallel.py:1986\u001b[39m, in \u001b[36mParallel.__call__\u001b[39m\u001b[34m(self, iterable)\u001b[39m\n\u001b[32m   1984\u001b[39m     output = \u001b[38;5;28mself\u001b[39m._get_sequential_output(iterable)\n\u001b[32m   1985\u001b[39m     \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[32m-> \u001b[39m\u001b[32m1986\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.return_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(output)\n\u001b[32m   1988\u001b[39m \u001b[38;5;66;03m# Let's create an ID that uniquely identifies the current call. If the\u001b[39;00m\n\u001b[32m   1989\u001b[39m \u001b[38;5;66;03m# call is interrupted early and that the same instance is immediately\u001b[39;00m\n\u001b[32m   1990\u001b[39m \u001b[38;5;66;03m# reused, this id will be used to prevent workers that were\u001b[39;00m\n\u001b[32m   1991\u001b[39m \u001b[38;5;66;03m# concurrently finalizing a task from the previous call to run the\u001b[39;00m\n\u001b[32m   1992\u001b[39m \u001b[38;5;66;03m# callback.\u001b[39;00m\n\u001b[32m   1993\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m._lock:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\jontx\\OneDrive\\Documentos\\.ZRIVE Applied Data Science\\zrive-ds\\.venv\\Lib\\site-packages\\joblib\\parallel.py:1914\u001b[39m, in \u001b[36mParallel._get_sequential_output\u001b[39m\u001b[34m(self, iterable)\u001b[39m\n\u001b[32m   1912\u001b[39m \u001b[38;5;28mself\u001b[39m.n_dispatched_batches += \u001b[32m1\u001b[39m\n\u001b[32m   1913\u001b[39m \u001b[38;5;28mself\u001b[39m.n_dispatched_tasks += \u001b[32m1\u001b[39m\n\u001b[32m-> \u001b[39m\u001b[32m1914\u001b[39m res = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1915\u001b[39m \u001b[38;5;28mself\u001b[39m.n_completed_tasks += \u001b[32m1\u001b[39m\n\u001b[32m   1916\u001b[39m \u001b[38;5;28mself\u001b[39m.print_progress()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\jontx\\OneDrive\\Documentos\\.ZRIVE Applied Data Science\\zrive-ds\\.venv\\Lib\\site-packages\\sklearn\\utils\\parallel.py:147\u001b[39m, in \u001b[36m_FuncWrapper.__call__\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    145\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m config_context(**config), warnings.catch_warnings():\n\u001b[32m    146\u001b[39m     warnings.filters = warning_filters\n\u001b[32m--> \u001b[39m\u001b[32m147\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\jontx\\OneDrive\\Documentos\\.ZRIVE Applied Data Science\\zrive-ds\\.venv\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:859\u001b[39m, in \u001b[36m_fit_and_score\u001b[39m\u001b[34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, score_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, split_progress, candidate_progress, error_score)\u001b[39m\n\u001b[32m    857\u001b[39m         estimator.fit(X_train, **fit_params)\n\u001b[32m    858\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m859\u001b[39m         \u001b[43mestimator\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mfit_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    861\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[32m    862\u001b[39m     \u001b[38;5;66;03m# Note fit time as time until error\u001b[39;00m\n\u001b[32m    863\u001b[39m     fit_time = time.time() - start_time\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\jontx\\OneDrive\\Documentos\\.ZRIVE Applied Data Science\\zrive-ds\\.venv\\Lib\\site-packages\\sklearn\\base.py:1365\u001b[39m, in \u001b[36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(estimator, *args, **kwargs)\u001b[39m\n\u001b[32m   1358\u001b[39m     estimator._validate_params()\n\u001b[32m   1360\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[32m   1361\u001b[39m     skip_parameter_validation=(\n\u001b[32m   1362\u001b[39m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[32m   1363\u001b[39m     )\n\u001b[32m   1364\u001b[39m ):\n\u001b[32m-> \u001b[39m\u001b[32m1365\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\jontx\\OneDrive\\Documentos\\.ZRIVE Applied Data Science\\zrive-ds\\.venv\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1384\u001b[39m, in \u001b[36mLogisticRegression.fit\u001b[39m\u001b[34m(self, X, y, sample_weight)\u001b[39m\n\u001b[32m   1381\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1382\u001b[39m     n_threads = \u001b[32m1\u001b[39m\n\u001b[32m-> \u001b[39m\u001b[32m1384\u001b[39m fold_coefs_ = \u001b[43mParallel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprefer\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprefer\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1385\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpath_func\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1386\u001b[39m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1387\u001b[39m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1388\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpos_class\u001b[49m\u001b[43m=\u001b[49m\u001b[43mclass_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1389\u001b[39m \u001b[43m        \u001b[49m\u001b[43mCs\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[43mC_\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1390\u001b[39m \u001b[43m        \u001b[49m\u001b[43ml1_ratio\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43ml1_ratio\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1391\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfit_intercept\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfit_intercept\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1392\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtol\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtol\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1393\u001b[39m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1394\u001b[39m \u001b[43m        \u001b[49m\u001b[43msolver\u001b[49m\u001b[43m=\u001b[49m\u001b[43msolver\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1395\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmulti_class\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmulti_class\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1396\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmax_iter\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmax_iter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1397\u001b[39m \u001b[43m        \u001b[49m\u001b[43mclass_weight\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mclass_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1398\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcheck_input\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m   1399\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1400\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcoef\u001b[49m\u001b[43m=\u001b[49m\u001b[43mwarm_start_coef_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1401\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpenalty\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpenalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1402\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmax_squared_sum\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmax_squared_sum\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1403\u001b[39m \u001b[43m        \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m=\u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1404\u001b[39m \u001b[43m        \u001b[49m\u001b[43mn_threads\u001b[49m\u001b[43m=\u001b[49m\u001b[43mn_threads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1405\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1406\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mclass_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwarm_start_coef_\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mzip\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mclasses_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwarm_start_coef\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1407\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1409\u001b[39m fold_coefs_, _, n_iter_ = \u001b[38;5;28mzip\u001b[39m(*fold_coefs_)\n\u001b[32m   1410\u001b[39m \u001b[38;5;28mself\u001b[39m.n_iter_ = np.asarray(n_iter_, dtype=np.int32)[:, \u001b[32m0\u001b[39m]\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\jontx\\OneDrive\\Documentos\\.ZRIVE Applied Data Science\\zrive-ds\\.venv\\Lib\\site-packages\\sklearn\\utils\\parallel.py:82\u001b[39m, in \u001b[36mParallel.__call__\u001b[39m\u001b[34m(self, iterable)\u001b[39m\n\u001b[32m     73\u001b[39m warning_filters = warnings.filters\n\u001b[32m     74\u001b[39m iterable_with_config_and_warning_filters = (\n\u001b[32m     75\u001b[39m     (\n\u001b[32m     76\u001b[39m         _with_config_and_warning_filters(delayed_func, config, warning_filters),\n\u001b[32m   (...)\u001b[39m\u001b[32m     80\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[32m     81\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m82\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config_and_warning_filters\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\jontx\\OneDrive\\Documentos\\.ZRIVE Applied Data Science\\zrive-ds\\.venv\\Lib\\site-packages\\joblib\\parallel.py:1986\u001b[39m, in \u001b[36mParallel.__call__\u001b[39m\u001b[34m(self, iterable)\u001b[39m\n\u001b[32m   1984\u001b[39m     output = \u001b[38;5;28mself\u001b[39m._get_sequential_output(iterable)\n\u001b[32m   1985\u001b[39m     \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[32m-> \u001b[39m\u001b[32m1986\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.return_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(output)\n\u001b[32m   1988\u001b[39m \u001b[38;5;66;03m# Let's create an ID that uniquely identifies the current call. If the\u001b[39;00m\n\u001b[32m   1989\u001b[39m \u001b[38;5;66;03m# call is interrupted early and that the same instance is immediately\u001b[39;00m\n\u001b[32m   1990\u001b[39m \u001b[38;5;66;03m# reused, this id will be used to prevent workers that were\u001b[39;00m\n\u001b[32m   1991\u001b[39m \u001b[38;5;66;03m# concurrently finalizing a task from the previous call to run the\u001b[39;00m\n\u001b[32m   1992\u001b[39m \u001b[38;5;66;03m# callback.\u001b[39;00m\n\u001b[32m   1993\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m._lock:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\jontx\\OneDrive\\Documentos\\.ZRIVE Applied Data Science\\zrive-ds\\.venv\\Lib\\site-packages\\joblib\\parallel.py:1914\u001b[39m, in \u001b[36mParallel._get_sequential_output\u001b[39m\u001b[34m(self, iterable)\u001b[39m\n\u001b[32m   1912\u001b[39m \u001b[38;5;28mself\u001b[39m.n_dispatched_batches += \u001b[32m1\u001b[39m\n\u001b[32m   1913\u001b[39m \u001b[38;5;28mself\u001b[39m.n_dispatched_tasks += \u001b[32m1\u001b[39m\n\u001b[32m-> \u001b[39m\u001b[32m1914\u001b[39m res = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1915\u001b[39m \u001b[38;5;28mself\u001b[39m.n_completed_tasks += \u001b[32m1\u001b[39m\n\u001b[32m   1916\u001b[39m \u001b[38;5;28mself\u001b[39m.print_progress()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\jontx\\OneDrive\\Documentos\\.ZRIVE Applied Data Science\\zrive-ds\\.venv\\Lib\\site-packages\\sklearn\\utils\\parallel.py:147\u001b[39m, in \u001b[36m_FuncWrapper.__call__\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    145\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m config_context(**config), warnings.catch_warnings():\n\u001b[32m    146\u001b[39m     warnings.filters = warning_filters\n\u001b[32m--> \u001b[39m\u001b[32m147\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\jontx\\OneDrive\\Documentos\\.ZRIVE Applied Data Science\\zrive-ds\\.venv\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:459\u001b[39m, in \u001b[36m_logistic_regression_path\u001b[39m\u001b[34m(X, y, pos_class, Cs, fit_intercept, max_iter, tol, verbose, solver, coef, class_weight, dual, penalty, intercept_scaling, multi_class, random_state, check_input, max_squared_sum, sample_weight, l1_ratio, n_threads)\u001b[39m\n\u001b[32m    455\u001b[39m l2_reg_strength = \u001b[32m1.0\u001b[39m / (C * sw_sum)\n\u001b[32m    456\u001b[39m iprint = [-\u001b[32m1\u001b[39m, \u001b[32m50\u001b[39m, \u001b[32m1\u001b[39m, \u001b[32m100\u001b[39m, \u001b[32m101\u001b[39m][\n\u001b[32m    457\u001b[39m     np.searchsorted(np.array([\u001b[32m0\u001b[39m, \u001b[32m1\u001b[39m, \u001b[32m2\u001b[39m, \u001b[32m3\u001b[39m]), verbose)\n\u001b[32m    458\u001b[39m ]\n\u001b[32m--> \u001b[39m\u001b[32m459\u001b[39m opt_res = \u001b[43moptimize\u001b[49m\u001b[43m.\u001b[49m\u001b[43mminimize\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    460\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    461\u001b[39m \u001b[43m    \u001b[49m\u001b[43mw0\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    462\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mL-BFGS-B\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    463\u001b[39m \u001b[43m    \u001b[49m\u001b[43mjac\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    464\u001b[39m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[43m=\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43ml2_reg_strength\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_threads\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    465\u001b[39m \u001b[43m    \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m=\u001b[49m\u001b[43m{\u001b[49m\n\u001b[32m    466\u001b[39m \u001b[43m        \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmaxiter\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_iter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    467\u001b[39m \u001b[43m        \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmaxls\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m50\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# default is 20\u001b[39;49;00m\n\u001b[32m    468\u001b[39m \u001b[43m        \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mgtol\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtol\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    469\u001b[39m \u001b[43m        \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mftol\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m64\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m \u001b[49m\u001b[43mnp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfinfo\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mfloat\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43meps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    470\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43m_get_additional_lbfgs_options_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43miprint\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43miprint\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    471\u001b[39m \u001b[43m    \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    472\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    473\u001b[39m n_iter_i = _check_optimize_result(\n\u001b[32m    474\u001b[39m     solver,\n\u001b[32m    475\u001b[39m     opt_res,\n\u001b[32m    476\u001b[39m     max_iter,\n\u001b[32m    477\u001b[39m     extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n\u001b[32m    478\u001b[39m )\n\u001b[32m    479\u001b[39m w0, loss = opt_res.x, opt_res.fun\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\jontx\\OneDrive\\Documentos\\.ZRIVE Applied Data Science\\zrive-ds\\.venv\\Lib\\site-packages\\scipy\\optimize\\_minimize.py:784\u001b[39m, in \u001b[36mminimize\u001b[39m\u001b[34m(fun, x0, args, method, jac, hess, hessp, bounds, constraints, tol, callback, options)\u001b[39m\n\u001b[32m    781\u001b[39m     res = _minimize_newtoncg(fun, x0, args, jac, hess, hessp, callback,\n\u001b[32m    782\u001b[39m                              **options)\n\u001b[32m    783\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m meth == \u001b[33m'\u001b[39m\u001b[33ml-bfgs-b\u001b[39m\u001b[33m'\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m784\u001b[39m     res = \u001b[43m_minimize_lbfgsb\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfun\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx0\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mjac\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbounds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    785\u001b[39m \u001b[43m                           \u001b[49m\u001b[43mcallback\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcallback\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    786\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m meth == \u001b[33m'\u001b[39m\u001b[33mtnc\u001b[39m\u001b[33m'\u001b[39m:\n\u001b[32m    787\u001b[39m     res = _minimize_tnc(fun, x0, args, jac, bounds, callback=callback,\n\u001b[32m    788\u001b[39m                         **options)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\jontx\\OneDrive\\Documentos\\.ZRIVE Applied Data Science\\zrive-ds\\.venv\\Lib\\site-packages\\scipy\\optimize\\_lbfgsb_py.py:469\u001b[39m, in \u001b[36m_minimize_lbfgsb\u001b[39m\u001b[34m(fun, x0, args, jac, bounds, disp, maxcor, ftol, gtol, eps, maxfun, maxiter, iprint, callback, maxls, finite_diff_rel_step, workers, **unknown_options)\u001b[39m\n\u001b[32m    461\u001b[39m _lbfgsb.setulb(m, x, low_bnd, upper_bnd, nbd, f, g, factr, pgtol, wa,\n\u001b[32m    462\u001b[39m                iwa, task, lsave, isave, dsave, maxls, ln_task)\n\u001b[32m    464\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m task[\u001b[32m0\u001b[39m] == \u001b[32m3\u001b[39m:\n\u001b[32m    465\u001b[39m     \u001b[38;5;66;03m# The minimization routine wants f and g at the current x.\u001b[39;00m\n\u001b[32m    466\u001b[39m     \u001b[38;5;66;03m# Note that interruptions due to maxfun are postponed\u001b[39;00m\n\u001b[32m    467\u001b[39m     \u001b[38;5;66;03m# until the completion of the current minimization iteration.\u001b[39;00m\n\u001b[32m    468\u001b[39m     \u001b[38;5;66;03m# Overwrite f and g:\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m469\u001b[39m     f, g = \u001b[43mfunc_and_grad\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    470\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m task[\u001b[32m0\u001b[39m] == \u001b[32m1\u001b[39m:\n\u001b[32m    471\u001b[39m     \u001b[38;5;66;03m# new iteration\u001b[39;00m\n\u001b[32m    472\u001b[39m     n_iterations += \u001b[32m1\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\jontx\\OneDrive\\Documentos\\.ZRIVE Applied Data Science\\zrive-ds\\.venv\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:403\u001b[39m, in \u001b[36mScalarFunction.fun_and_grad\u001b[39m\u001b[34m(self, x)\u001b[39m\n\u001b[32m    401\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m np.array_equal(x, \u001b[38;5;28mself\u001b[39m.x):\n\u001b[32m    402\u001b[39m     \u001b[38;5;28mself\u001b[39m._update_x(x)\n\u001b[32m--> \u001b[39m\u001b[32m403\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_update_fun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    404\u001b[39m \u001b[38;5;28mself\u001b[39m._update_grad()\n\u001b[32m    405\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.f, \u001b[38;5;28mself\u001b[39m.g\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\jontx\\OneDrive\\Documentos\\.ZRIVE Applied Data Science\\zrive-ds\\.venv\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:353\u001b[39m, in \u001b[36mScalarFunction._update_fun\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    351\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_update_fun\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m    352\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m.f_updated:\n\u001b[32m--> \u001b[39m\u001b[32m353\u001b[39m         fx = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_wrapped_fun\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    354\u001b[39m         \u001b[38;5;28mself\u001b[39m._nfev += \u001b[32m1\u001b[39m\n\u001b[32m    355\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m fx < \u001b[38;5;28mself\u001b[39m._lowest_f:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\jontx\\OneDrive\\Documentos\\.ZRIVE Applied Data Science\\zrive-ds\\.venv\\Lib\\site-packages\\scipy\\_lib\\_util.py:590\u001b[39m, in \u001b[36m_ScalarFunctionWrapper.__call__\u001b[39m\u001b[34m(self, x)\u001b[39m\n\u001b[32m    587\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[32m    588\u001b[39m     \u001b[38;5;66;03m# Send a copy because the user may overwrite it.\u001b[39;00m\n\u001b[32m    589\u001b[39m     \u001b[38;5;66;03m# The user of this class might want `x` to remain unchanged.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m590\u001b[39m     fx = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    591\u001b[39m     \u001b[38;5;28mself\u001b[39m.nfev += \u001b[32m1\u001b[39m\n\u001b[32m    593\u001b[39m     \u001b[38;5;66;03m# Make sure the function returns a true scalar\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\jontx\\OneDrive\\Documentos\\.ZRIVE Applied Data Science\\zrive-ds\\.venv\\Lib\\site-packages\\scipy\\optimize\\_optimize.py:80\u001b[39m, in \u001b[36mMemoizeJac.__call__\u001b[39m\u001b[34m(self, x, *args)\u001b[39m\n\u001b[32m     78\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, x, *args):\n\u001b[32m     79\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\" returns the function value \"\"\"\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m80\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_compute_if_needed\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     81\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._value\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\jontx\\OneDrive\\Documentos\\.ZRIVE Applied Data Science\\zrive-ds\\.venv\\Lib\\site-packages\\scipy\\optimize\\_optimize.py:74\u001b[39m, in \u001b[36mMemoizeJac._compute_if_needed\u001b[39m\u001b[34m(self, x, *args)\u001b[39m\n\u001b[32m     72\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m np.all(x == \u001b[38;5;28mself\u001b[39m.x) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._value \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m.jac \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m     73\u001b[39m     \u001b[38;5;28mself\u001b[39m.x = np.asarray(x).copy()\n\u001b[32m---> \u001b[39m\u001b[32m74\u001b[39m     fg = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     75\u001b[39m     \u001b[38;5;28mself\u001b[39m.jac = fg[\u001b[32m1\u001b[39m]\n\u001b[32m     76\u001b[39m     \u001b[38;5;28mself\u001b[39m._value = fg[\u001b[32m0\u001b[39m]\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\jontx\\OneDrive\\Documentos\\.ZRIVE Applied Data Science\\zrive-ds\\.venv\\Lib\\site-packages\\sklearn\\linear_model\\_linear_loss.py:316\u001b[39m, in \u001b[36mLinearModelLoss.loss_gradient\u001b[39m\u001b[34m(self, coef, X, y, sample_weight, l2_reg_strength, n_threads, raw_prediction)\u001b[39m\n\u001b[32m    313\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    314\u001b[39m     weights, intercept = \u001b[38;5;28mself\u001b[39m.weight_intercept(coef)\n\u001b[32m--> \u001b[39m\u001b[32m316\u001b[39m loss, grad_pointwise = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbase_loss\u001b[49m\u001b[43m.\u001b[49m\u001b[43mloss_gradient\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    317\u001b[39m \u001b[43m    \u001b[49m\u001b[43my_true\u001b[49m\u001b[43m=\u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    318\u001b[39m \u001b[43m    \u001b[49m\u001b[43mraw_prediction\u001b[49m\u001b[43m=\u001b[49m\u001b[43mraw_prediction\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    319\u001b[39m \u001b[43m    \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m=\u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    320\u001b[39m \u001b[43m    \u001b[49m\u001b[43mn_threads\u001b[49m\u001b[43m=\u001b[49m\u001b[43mn_threads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    321\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    322\u001b[39m sw_sum = n_samples \u001b[38;5;28;01mif\u001b[39;00m sample_weight \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m np.sum(sample_weight)\n\u001b[32m    323\u001b[39m loss = loss.sum() / sw_sum\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\jontx\\OneDrive\\Documentos\\.ZRIVE Applied Data Science\\zrive-ds\\.venv\\Lib\\site-packages\\sklearn\\_loss\\loss.py:258\u001b[39m, in \u001b[36mBaseLoss.loss_gradient\u001b[39m\u001b[34m(self, y_true, raw_prediction, sample_weight, loss_out, gradient_out, n_threads)\u001b[39m\n\u001b[32m    255\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m gradient_out.ndim == \u001b[32m2\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m gradient_out.shape[\u001b[32m1\u001b[39m] == \u001b[32m1\u001b[39m:\n\u001b[32m    256\u001b[39m     gradient_out = gradient_out.squeeze(\u001b[32m1\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m258\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcloss\u001b[49m\u001b[43m.\u001b[49m\u001b[43mloss_gradient\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    259\u001b[39m \u001b[43m    \u001b[49m\u001b[43my_true\u001b[49m\u001b[43m=\u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    260\u001b[39m \u001b[43m    \u001b[49m\u001b[43mraw_prediction\u001b[49m\u001b[43m=\u001b[49m\u001b[43mraw_prediction\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    261\u001b[39m \u001b[43m    \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m=\u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    262\u001b[39m \u001b[43m    \u001b[49m\u001b[43mloss_out\u001b[49m\u001b[43m=\u001b[49m\u001b[43mloss_out\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    263\u001b[39m \u001b[43m    \u001b[49m\u001b[43mgradient_out\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgradient_out\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    264\u001b[39m \u001b[43m    \u001b[49m\u001b[43mn_threads\u001b[49m\u001b[43m=\u001b[49m\u001b[43mn_threads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    265\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    266\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m loss_out, gradient_out\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "gss = GroupShuffleSplit(n_splits=1, test_size=0.15, random_state=42)\n",
    "train_val_idx, test_idx = next(gss.split(df_feature, groups=df_feature[GROUP]))\n",
    "tv = df_feature.iloc[train_val_idx].reset_index(drop=True)\n",
    "test = df_feature.iloc[test_idx].reset_index(drop=True)\n",
    "X_test, y_test = test[FEATURES], test[TARGET]\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_test = scaler.fit(X_test)\n",
    "\n",
    "sgk = StratifiedGroupKFold(n_splits = 5, shuffle=True, random_state=43)\n",
    "reg = [1, 10, 50]\n",
    "\n",
    "for a in reg:\n",
    "    clf = LogisticRegression(C = a)\n",
    "    score = cross_val_score(clf, tv[FEATURES], tv[TARGET], groups=tv[GROUP], cv=sgk, scoring = 'precision')\n",
    "    \n",
    "    print(f'Score for C = {a} on cross validation is {score}')\n",
    "    print(f'Mean score for C = {a} on cross validation is {score.mean()}')\n",
    "# for fold, (tr_idx, val_idx) in enumerate(sgk.split(tv[FEATURES], y = tv[TARGET], groups=tv[GROUP])):\n",
    "#     train = tv.iloc[tr_idx]\n",
    "#     val = tv.iloc[val_idx]\n",
    "#     X_train, y_train = train[FEATURES], train[TARGET]\n",
    "#     X_val, y_val = val[FEATURES], val[TARGET]\n",
    "\n",
    "#     clf.fit(X_train, y_train)\n",
    "\n",
    "#     d_val = clf.decision_function(X_val)\n",
    "\n",
    "#     prec, rec, thr = precision_recall_curve(y_val, d_val)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "38cd9b14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK: test users disjoint from train/val pool.\n",
      "fold 1: users train=1032 val=257 pos_rate_tr=0.0144 pos_rate_val=0.0148\n",
      "fold 2: users train=1032 val=257 pos_rate_tr=0.0146 pos_rate_val=0.0140\n",
      "fold 3: users train=1031 val=258 pos_rate_tr=0.0146 pos_rate_val=0.0141\n",
      "fold 4: users train=1030 val=259 pos_rate_tr=0.0145 pos_rate_val=0.0147\n",
      "fold 5: users train=1031 val=258 pos_rate_tr=0.0144 pos_rate_val=0.0149\n",
      "All folds OK.\n"
     ]
    }
   ],
   "source": [
    "# 1) test vs train/val pool\n",
    "users_tv, users_test = set(tv[GROUP].unique()), set(test[GROUP].unique())\n",
    "assert users_tv.isdisjoint(users_test), \"Users leak between tv and test!\"\n",
    "print(\"OK: test users disjoint from train/val pool.\")\n",
    "\n",
    "# 2) per-fold disjointness + quick diagnostics\n",
    "for fold, (tr_idx, va_idx) in enumerate(sgk.split(tv[x_var], y=tv[TARGET], groups=tv[GROUP]), 1):\n",
    "    u_tr  = set(tv.iloc[tr_idx][GROUP].unique())\n",
    "    u_val = set(tv.iloc[va_idx][GROUP].unique())\n",
    "    assert u_tr.isdisjoint(u_val), f\"Fold {fold}: train/val share users!\"\n",
    "    assert u_tr.isdisjoint(users_test) and u_val.isdisjoint(users_test), f\"Fold {fold}: leakage vs test!\"\n",
    "    print(f\"fold {fold}: users train={len(u_tr)} val={len(u_val)} \"\n",
    "          f\"pos_rate_tr={tv.iloc[tr_idx][TARGET].mean():.4f} \"\n",
    "          f\"pos_rate_val={tv.iloc[va_idx][TARGET].mean():.4f}\")\n",
    "print(\"All folds OK.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba877d17",
   "metadata": {},
   "source": [
    "## PRE-PROCESSING"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3da09491",
   "metadata": {},
   "source": [
    "I have considered that some features like 'days_since_purchase_variant_id' or 'days_since_purchase_product_type' are some kind of data that won´t be available in production as it is considering the time past since the purchase, but I am trying to predict whether a customer could potentially buy or not a product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "74fbbe9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "target = ['outcome']\n",
    "cat_cols = ['product_type', 'vendor']\n",
    "exclude_cols = ['days_since_purchase_variant_id', 'days_since_purchase_product_type']\n",
    "\n",
    "exclude = target + cat_cols + exclude_cols\n",
    "numeric_cols = [col for col in df_feature.columns if col not in exclude]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "ff19f33b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>variant_id</th>\n",
       "      <th>product_type</th>\n",
       "      <th>order_id</th>\n",
       "      <th>user_id</th>\n",
       "      <th>created_at</th>\n",
       "      <th>order_date</th>\n",
       "      <th>user_order_seq</th>\n",
       "      <th>outcome</th>\n",
       "      <th>ordered_before</th>\n",
       "      <th>abandoned_before</th>\n",
       "      <th>active_snoozed</th>\n",
       "      <th>set_as_regular</th>\n",
       "      <th>normalised_price</th>\n",
       "      <th>discount_pct</th>\n",
       "      <th>vendor</th>\n",
       "      <th>global_popularity</th>\n",
       "      <th>count_adults</th>\n",
       "      <th>count_children</th>\n",
       "      <th>count_babies</th>\n",
       "      <th>count_pets</th>\n",
       "      <th>people_ex_baby</th>\n",
       "      <th>days_since_purchase_variant_id</th>\n",
       "      <th>avg_days_to_buy_variant_id</th>\n",
       "      <th>std_days_to_buy_variant_id</th>\n",
       "      <th>days_since_purchase_product_type</th>\n",
       "      <th>avg_days_to_buy_product_type</th>\n",
       "      <th>std_days_to_buy_product_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>33826472919172</td>\n",
       "      <td>ricepastapulses</td>\n",
       "      <td>2807985930372</td>\n",
       "      <td>3482464092292</td>\n",
       "      <td>2020-10-05 16:46:19</td>\n",
       "      <td>2020-10-05</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.081052</td>\n",
       "      <td>0.053512</td>\n",
       "      <td>clearspring</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>31.134053</td>\n",
       "      <td>30.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>24.27618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>33826472919172</td>\n",
       "      <td>ricepastapulses</td>\n",
       "      <td>2808027644036</td>\n",
       "      <td>3466586718340</td>\n",
       "      <td>2020-10-05 17:59:51</td>\n",
       "      <td>2020-10-05</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.081052</td>\n",
       "      <td>0.053512</td>\n",
       "      <td>clearspring</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>31.134053</td>\n",
       "      <td>30.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>24.27618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>33826472919172</td>\n",
       "      <td>ricepastapulses</td>\n",
       "      <td>2808099078276</td>\n",
       "      <td>3481384026244</td>\n",
       "      <td>2020-10-05 20:08:53</td>\n",
       "      <td>2020-10-05</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.081052</td>\n",
       "      <td>0.053512</td>\n",
       "      <td>clearspring</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>31.134053</td>\n",
       "      <td>30.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>24.27618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>33826472919172</td>\n",
       "      <td>ricepastapulses</td>\n",
       "      <td>2808393957508</td>\n",
       "      <td>3291363377284</td>\n",
       "      <td>2020-10-06 08:57:59</td>\n",
       "      <td>2020-10-06</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.081052</td>\n",
       "      <td>0.053512</td>\n",
       "      <td>clearspring</td>\n",
       "      <td>0.038462</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>31.134053</td>\n",
       "      <td>30.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>24.27618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>33826472919172</td>\n",
       "      <td>ricepastapulses</td>\n",
       "      <td>2808434524292</td>\n",
       "      <td>3479090790532</td>\n",
       "      <td>2020-10-06 10:50:23</td>\n",
       "      <td>2020-10-06</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.081052</td>\n",
       "      <td>0.053512</td>\n",
       "      <td>clearspring</td>\n",
       "      <td>0.038462</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>31.134053</td>\n",
       "      <td>30.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>24.27618</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       variant_id     product_type       order_id        user_id  \\\n",
       "0  33826472919172  ricepastapulses  2807985930372  3482464092292   \n",
       "1  33826472919172  ricepastapulses  2808027644036  3466586718340   \n",
       "2  33826472919172  ricepastapulses  2808099078276  3481384026244   \n",
       "3  33826472919172  ricepastapulses  2808393957508  3291363377284   \n",
       "5  33826472919172  ricepastapulses  2808434524292  3479090790532   \n",
       "\n",
       "           created_at order_date  user_order_seq  outcome  ordered_before  \\\n",
       "0 2020-10-05 16:46:19 2020-10-05               3      0.0             0.0   \n",
       "1 2020-10-05 17:59:51 2020-10-05               2      0.0             0.0   \n",
       "2 2020-10-05 20:08:53 2020-10-05               4      0.0             0.0   \n",
       "3 2020-10-06 08:57:59 2020-10-06               2      0.0             0.0   \n",
       "5 2020-10-06 10:50:23 2020-10-06               3      0.0             0.0   \n",
       "\n",
       "   abandoned_before  active_snoozed  set_as_regular  normalised_price  \\\n",
       "0               0.0             0.0             0.0          0.081052   \n",
       "1               0.0             0.0             0.0          0.081052   \n",
       "2               0.0             0.0             0.0          0.081052   \n",
       "3               0.0             0.0             0.0          0.081052   \n",
       "5               0.0             0.0             0.0          0.081052   \n",
       "\n",
       "   discount_pct       vendor  global_popularity  count_adults  count_children  \\\n",
       "0      0.053512  clearspring           0.000000           2.0             0.0   \n",
       "1      0.053512  clearspring           0.000000           2.0             0.0   \n",
       "2      0.053512  clearspring           0.000000           2.0             0.0   \n",
       "3      0.053512  clearspring           0.038462           2.0             0.0   \n",
       "5      0.053512  clearspring           0.038462           2.0             0.0   \n",
       "\n",
       "   count_babies  count_pets  people_ex_baby  days_since_purchase_variant_id  \\\n",
       "0           0.0         0.0             2.0                            33.0   \n",
       "1           0.0         0.0             2.0                            33.0   \n",
       "2           0.0         0.0             2.0                            33.0   \n",
       "3           0.0         0.0             2.0                            33.0   \n",
       "5           0.0         0.0             2.0                            33.0   \n",
       "\n",
       "   avg_days_to_buy_variant_id  std_days_to_buy_variant_id  \\\n",
       "0                        42.0                   31.134053   \n",
       "1                        42.0                   31.134053   \n",
       "2                        42.0                   31.134053   \n",
       "3                        42.0                   31.134053   \n",
       "5                        42.0                   31.134053   \n",
       "\n",
       "   days_since_purchase_product_type  avg_days_to_buy_product_type  \\\n",
       "0                              30.0                          30.0   \n",
       "1                              30.0                          30.0   \n",
       "2                              30.0                          30.0   \n",
       "3                              30.0                          30.0   \n",
       "5                              30.0                          30.0   \n",
       "\n",
       "   std_days_to_buy_product_type  \n",
       "0                      24.27618  \n",
       "1                      24.27618  \n",
       "2                      24.27618  \n",
       "3                      24.27618  \n",
       "5                      24.27618  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_feature['created_at'] = pd.to_datetime(df_feature['created_at'])\n",
    "df_feature['order_date'] = pd.to_datetime(df_feature['order_date'])\n",
    "df_feature.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36a345d6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "zrive-env",
   "language": "python",
   "name": "zrive-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
